{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOEe725tkpJXsrnCqjjcBNv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ishaan1977/ChatbotAssistant/blob/main/ChatbotAssistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlzZLmLAgi3t",
        "outputId": "88784c31-586e-4d35-e9da-2c33ba6977c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.3.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.3.74)\n",
            "Collecting groq<1,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.30.0->langchain-groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.14.1)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain-groq) (0.4.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain-groq) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain-groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain-groq) (25.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.30.0->langchain-groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-groq) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-groq) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.72->langchain-groq) (2.5.0)\n",
            "Downloading langchain_groq-0.3.7-py3-none-any.whl (16 kB)\n",
            "Downloading groq-0.31.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.31.0 langchain-groq-0.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
        "llm = ChatGroq(model=\"llama3-70b-8192\")\n",
        "response = llm.invoke(\"Explain langchain in one sentence.\")\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MICVQLvtb5IJ",
        "outputId": "47917008-4be4-4597-910f-1b1294414a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain is a framework that enables the creation of AI models that can learn from and generate text, code, and other forms of data, allowing for the development of more advanced and flexible AI applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "W_VbZo5UgZRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful chatbot that answers clearly and concisely\"),\n",
        "    (\"user\", \"{question}\")\n",
        "])\n",
        "chain = LLMChain(llm=llm, prompt=template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-em1IFKliCim",
        "outputId": "144c68c9-5a2d-4bfb-f002-b8d37e492fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2885558883.py:5: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=template)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke({\"question\": \"What is LangChain?\"})\n",
        "print(response[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9B4Yp0kjBBR",
        "outputId": "8ccc7809-3839-47ea-8361-dc76ecbc4607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain is an open-source framework that enables developers to build and deploy AI-powered language models and applications more efficiently. It provides a modular architecture that allows users to chain together multiple language models, processing tools, and data sources to create complex language processing pipelines.\n",
            "\n",
            "LangChain aims to simplify the development of language AI applications, making it easier to integrate and customize language models, and to build more accurate and robust language understanding systems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a pure chatbot which can answer by remembering chat"
      ],
      "metadata": {
        "id": "OqDIlTO5k-D8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "zPv0urCckSuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(return_messages=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzp4rIVLkyvL",
        "outputId": "e192305d-3267-4571-accc-3958e62de23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3614923015.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(return_messages=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import ConversationChain"
      ],
      "metadata": {
        "id": "E9G3idhDlmqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation= ConversationChain(\n",
        "    llm=llm,\n",
        "    memory= memory\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MufySTcQlGAi",
        "outputId": "09199241-2a66-44e4-a37c-3a71009f1f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3839634416.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
            "  conversation= ConversationChain(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "below is like calling a response from chatbot once."
      ],
      "metadata": {
        "id": "EJwr0FPCmJ-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = conversation.predict(input=\"Hi, I’m learning LangChain. Can you be my tutor?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ1_RyaHlt7Y",
        "outputId": "33e47c0c-4b96-4c1c-eeb6-335d95f4bf26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello there! I'd be delighted to be your LangChain tutor! LangChain is a fascinating topic, and I'm excited to help you explore its possibilities. As a brief introduction, LangChain is a large language model capable of generating human-like text based on the input prompts it receives. It's been trained on a massive dataset of text from various sources, which enables it to understand and respond to a wide range of topics and questions.\n",
            "\n",
            "Before we dive in, could you tell me a bit more about what specific aspects of LangChain you'd like to focus on? Are you interested in learning about its applications, its architecture, or perhaps how to fine-tune it for your own projects?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now making a chatbot like chatting in loop\n"
      ],
      "metadata": {
        "id": "QXKK6bAomOMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input= input(\"You: \")\n",
        "  if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "    print(\"Chat ended.\")\n",
        "    break\n",
        "  response = conversation.predict(input=user_input)\n",
        "  print(\"Bot:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI6Y6tZLmHhb",
        "outputId": "87edff58-d157-40be-ed55-e882ae321b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: Hey dude\n",
            "Bot: No worries about the casual greeting! I'm still excited to help you with LangChain. So, to follow up on my previous question, what's been drawing you to LangChain? Are you looking to build a specific project, or do you want to understand the underlying technology better? Perhaps you've heard about its potential in areas like language translation, text summarization, or chatbots? Let me know, and I can tailor our conversation to your interests!\n",
            "You: i was trying to build some you only\n",
            "Bot: It sounds like you were trying to build something with LangChain, but you're not sure where to start or need some guidance. That's completely understandable! LangChain can be a powerful tool, but it can be overwhelming if you're new to large language models or natural language processing.\n",
            "\n",
            "Can you tell me a bit more about what you were trying to build? Was it a chatbot, a language translation tool, or something else entirely? The more information you can provide, the better I'll be able to assist you. If you have any code or prompts you've tried so far, feel free to share those as well, and I can help you troubleshoot or suggest next steps.\n",
            "You: quit\n",
            "Chat ended.\n"
          ]
        }
      ]
    }
  ]
}